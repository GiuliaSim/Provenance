{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/home/giulia/Provenance')\n",
    "import ipynb.fs.full.provenance as pr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "# Specify where to save the processed files as savepath\n",
    "savepath = 'results/OneHot_prov/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN - Rows:  4  Features:  3\n",
      "     checking  duration   credit_history\n",
      "0   check_low         6    debt_critical\n",
      "1   check_mid        48  debt_onSchedule\n",
      "2  check_none        12    debt_critical\n",
      "3   check_low        42  debt_onSchedule\n"
     ]
    }
   ],
   "source": [
    "# Files get loaded from fairCorrect github repository\n",
    "url = 'https://raw.githubusercontent.com/vladoxNCL/fairCorrect/master/Datasets/'\n",
    "df = pd.read_csv(url + 'german.csv', header=None)\n",
    "\n",
    "# Data needed column names\n",
    "df.columns = ['checking', 'duration', 'credit_history', 'purpose', 'credit_amount',\n",
    "              'savings', 'employment', 'inst_rate', 'personal_status', 'other_debtors',\n",
    "              'residence_time', 'property', 'age', 'other_inst', 'housing', 'num_credits',\n",
    "              'job', 'dependants', 'phone', 'foreigner', 'label']\n",
    "\n",
    "# Turn criptic values into interpretable form\n",
    "df = df.replace({'checking': {'A11': 'check_low', 'A12': 'check_mid', 'A13': 'check_high',\n",
    "                              'A14': 'check_none'},\n",
    "                 'credit_history': {'A30': 'debt_none', 'A31': 'debt_noneBank',\n",
    "                                    'A32': 'debt_onSchedule','A33': 'debt_delay',\n",
    "                                    'A34': 'debt_critical'},\n",
    "                 'purpose': {'A40': 'pur_newCar', 'A41': 'pur_usedCar',\n",
    "                             'A42': 'pur_furniture', 'A43': 'pur_tv',\n",
    "                             'A44': 'pur_appliance', 'A45': 'pur_repairs',\n",
    "                             'A46': 'pur_education', 'A47': 'pur_vacation',\n",
    "                             'A48': 'pur_retraining', 'A49': 'pur_business',\n",
    "                             'A410': 'pur_other'},\n",
    "                 'savings': {'A61': 'sav_small', 'A62': 'sav_medium', 'A63': 'sav_large',\n",
    "                             'A64': 'sav_xlarge', 'A65': 'sav_none'},\n",
    "                 'employment': {'A71': 'emp_unemployed', 'A72': 'emp_lessOne',\n",
    "                                'A73': 'emp_lessFour', 'A74': 'emp_lessSeven',\n",
    "                                'A75': 'emp_moreSeven'},\n",
    "                 'other_debtors': {'A101': 'debtor_none', 'A102': 'debtor_coApp',\n",
    "                                   'A103': 'debtor_guarantor'},\n",
    "                 'property': {'A121': 'prop_realEstate', 'A122': 'prop_agreement',\n",
    "                              'A123': 'prop_car', 'A124': 'prop_none'},\n",
    "                 'other_inst': {'A141': 'oi_bank', 'A142': 'oi_stores', 'A143': 'oi_none'},\n",
    "                 'housing': {'A151': 'hous_rent', 'A152': 'hous_own', 'A153': 'hous_free'},\n",
    "                 'job': {'A171': 'job_unskilledNR', 'A172': 'job_unskilledR',\n",
    "                         'A173': 'job_skilled', 'A174': 'job_highSkill'},\n",
    "                 'phone': {'A191': 0, 'A192': 1},\n",
    "                 'foreigner': {'A201': 1, 'A202': 0},\n",
    "                 'label': {2: 0}})\n",
    "\n",
    "# More criptic values translating\n",
    "df['status'] = np.where(df.personal_status == 'A91', 'divorced',\n",
    "                        np.where(df.personal_status == 'A92', 'divorced', \n",
    "                                 np.where(df.personal_status == 'A93', 'single',\n",
    "                                          np.where(df.personal_status == 'A95', 'single',\n",
    "                                                   'married'))))\n",
    "# Translate gender values\n",
    "df['gender'] = np.where(df.personal_status == 'A92', 0,\n",
    "                        np.where(df.personal_status == 'A95', 0,\n",
    "                                 1))\n",
    "\n",
    "# Drop personal_status column\n",
    "df = df.drop(['personal_status'], axis=1)\n",
    "\n",
    "\n",
    "df = df[:4]\n",
    "df = df[['checking', 'duration', 'credit_history']]\n",
    "# Create a new provenance document and input entities \n",
    "p = pr.Provenance(df, savepath)\n",
    "\n",
    "m, n= df.shape\n",
    "print(\"IN - Rows: \", m, \" Features: \",n)\n",
    "print(df)\n",
    "\n",
    "columns_in = df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   duration  check_low  check_mid  check_none  debt_critical  debt_onSchedule\n",
      "0         6          1          0           0              1                0\n",
      "1        48          0          1           0              0                1\n",
      "2        12          0          0           1              1                0\n",
      "3        42          1          0           0              0                1\n"
     ]
    }
   ],
   "source": [
    "# One-hot encode categorical columns\n",
    "onehot_col = ['checking', 'credit_history', 'purpose', 'savings', 'employment', 'other_debtors', 'property',\n",
    "       'other_inst', 'housing', 'job', 'status']\n",
    "onehot_col = ['checking', 'credit_history']\n",
    "\n",
    "onehot_col_map = {}\n",
    "\n",
    "for c in onehot_col:\n",
    "    #Get map column-val\n",
    "    unique_val = df[c].unique().tolist()\n",
    "    onehot_col_map[c] = unique_val\n",
    "    \n",
    "    dummies = []\n",
    "    dummies.append(pd.get_dummies(df[c]))\n",
    "    df_dummies = pd.concat(dummies, axis = 1)\n",
    "    df = pd.concat((df, df_dummies), axis = 1)\n",
    "    df = df.drop([c], axis = 1)\n",
    "    \n",
    "print(df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_prov_onehot_encode function took 11.551 ms\n"
     ]
    }
   ],
   "source": [
    "#GET PROVENANCE\n",
    "d = p.get_prov_onehot_encode(df, onehot_col, onehot_col_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#namefile = savepath + 'onehot_prov'\n",
    "#p.save_all_graph(namefile)\n",
    "#Image(namefile + '.png')\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
